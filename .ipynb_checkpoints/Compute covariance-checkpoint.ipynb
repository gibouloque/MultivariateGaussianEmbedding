{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.Lat_cov_estimation import estimate_4lat, generate_DCT_trans\n",
    "import numpy as np\n",
    "\n",
    "import rawpy\n",
    "\n",
    "import code.image_conversions as imc\n",
    "\n",
    "from os import path, makedirs, listdir, remove\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     11,
     22
    ]
   },
   "outputs": [],
   "source": [
    "c_quant_95 = np.array([\\\n",
    "        [ 2,  1,  1,  2,  2,  4,  5,  6],\\\n",
    "        [ 1,  1,  1,  2,  3,  6,  6,  6],\\\n",
    "        [ 1,  1,  2,  2,  4,  6,  7,  6],\\\n",
    "        [ 1,  2,  2,  3,  5,  9,  8,  6],\\\n",
    "        [ 2,  2,  4,  6,  7, 11, 10,  8],\\\n",
    "        [ 2,  4,  6,  6,  8, 10, 11,  9],\\\n",
    "        [ 5,  6,  8,  9, 10, 12, 12, 10],\\\n",
    "        [ 7,  9, 10, 10, 11, 10, 10, 10]])\n",
    "\n",
    "# Quant table at 85% (convert)\n",
    "c_quant_85 = np.array([\\\n",
    "     [ 5,  3,  3,  5,  7, 12, 15, 18],\\\n",
    "     [ 4,  4,  4,  6,  8, 17, 18, 17],\\\n",
    "     [ 4,  4,  5,  7, 12, 17, 21, 17],\\\n",
    "     [ 4,  5,  7,  9, 15, 26, 24, 19],\\\n",
    "     [ 5,  7, 11, 17, 20, 33, 31, 23],\\\n",
    "     [ 7, 11, 17, 19, 24, 31, 34, 28],\\\n",
    "     [15, 19, 23, 26, 31, 36, 36, 30],\\\n",
    "     [22, 28, 29, 29, 34, 30, 31, 30]])\n",
    "\n",
    "# Quant table at 75% (convert)\n",
    "c_quant_75 = np.array([\\\n",
    "        [ 8,  6,  5,  8, 12, 20, 26, 31],\\\n",
    "        [ 6,  6,  7, 10, 13, 29, 30, 28],\\\n",
    "        [ 7,  7,  8, 12, 20, 29, 35, 28],\\\n",
    "        [ 7,  9, 11, 15, 26, 44, 40, 31],\\\n",
    "        [ 9, 11, 19, 28, 34, 55, 52, 39],\\\n",
    "        [12, 18, 28, 32, 41, 52, 57, 46],\\\n",
    "        [25, 32, 39, 44, 52, 61, 60, 51],\\\n",
    "        [36, 46, 48, 49, 56, 50, 52, 50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_params = np.load('data/BOSSBase/BOSS_noise_params_robust.npy', allow_pickle=True).item()\n",
    "dataset = np.load('data/BOSSBase/BOSSBase_dataset.npy', allow_pickle=True).item()\n",
    "orient_dict = np.load('data/BOSSBase/orient_dict_BossBase.npy', allow_pickle=True).item()\n",
    "dataset_max_val = np.load('data/BOSSBase/Camera_BOSS_max_val.npy', allow_pickle=True).item()\n",
    "im_idx = np.load('data/BOSSBase/BOSS_edge_crop_idx.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'datasets/BOSSBase/'\n",
    "RAW_path = path.join( base_path, 'RAW')\n",
    "RAW_files = listdir(RAW_path)\n",
    "\n",
    "# Remove M9\n",
    "RAW_files = [f for f in RAW_files if dataset[f][0] != 'M9 Digital Camera']\n",
    "RAW_files_path = [RAW_path + file for file in RAW_files if path.isfile(RAW_path + file)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pipeline matrix estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso\n",
    "def ridge_solve(a,b,alpha=1):\n",
    "    clf = Ridge(alpha)\n",
    "    clf.fit(a, b) \n",
    "    return(clf.coef_)\n",
    "def lasso_solve(a,b,alpha=1):\n",
    "    clf = Lasso(alpha)\n",
    "    clf.fit(a, b) \n",
    "    return(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     22
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def center_crop(im, newWidth, newHeight, add_margin=0):\n",
    "    width, height = im.shape[0:2]  # Get dimensions\n",
    "    if newWidth > width or newHeight > height:\n",
    "        newWidth, newHeight = newHeight, newWidth\n",
    "    \n",
    "# Here we simply compute the first and last indices of pixels' central area.\n",
    "    left = (width - newWidth) // 2\n",
    "    top = (height - newHeight) // 2\n",
    "    right = (width + newWidth) // 2\n",
    "    bottom = (height + newHeight) // 2\n",
    "# and merely return the pixels from this area ...\n",
    "    if add_margin==1:\n",
    "        return(im[left-1:right+1, top-1:bottom+1])\n",
    "    elif add_margin==3:\n",
    "        return(im[left-9:right+9, top-9:bottom+9])\n",
    "    elif add_margin==24:\n",
    "        return(im[left-24:right, top-24:bottom])\n",
    "    elif add_margin==0:\n",
    "        return(im[left:right, top:bottom])\n",
    "    else:\n",
    "        print('Unimplemented margin')\n",
    "        return(None)\n",
    "def generate_sample(RAW_path, orientation,a,b=0,lvl_max=2**16):\n",
    "\n",
    "    RAW_im = rawpy.imread(RAW_path)\n",
    "    \n",
    "    RAW_im.raw_image_visible[:,:] = lvl_max/4\n",
    "    sensor_noise = a*RAW_im.raw_image_visible[:,:]+b\n",
    "    sensor_noise[sensor_noise < 0] = 0 \n",
    "    new_im = np.random.normal(loc=RAW_im.raw_image_visible[:,:], scale= np.sqrt(sensor_noise))\n",
    "    new_im[new_im <0] = 0\n",
    "    new_im[new_im > lvl_max] = lvl_max\n",
    "    RAW_im.raw_image_visible[:,:] = new_im \n",
    "    \n",
    "    rgb = RAW_im.postprocess(params)\n",
    "    (h,w) = RAW_im.raw_image_visible.shape\n",
    "    \n",
    "    crop_shape = 264*6\n",
    "    RAW = RAW_im.raw_image_visible[:,:]\n",
    "    if orientation == 5:\n",
    "        RAW = np.rot90(RAW,1)\n",
    "\n",
    "    elif orientation == 6:\n",
    "        RAW = np.rot90(RAW,-1)\n",
    "        \n",
    "    RAW = center_crop(RAW,crop_shape, crop_shape,add_margin=1)\n",
    "    grey = center_crop(imc.rgb2gray((rgb/(2**16-1))*255), crop_shape, crop_shape) #Keep floats\n",
    "    #res = np.array(Image.fromarray(grey[:,:]).resize((crop_shape//3, crop_shape//3), Image.LANCZOS))\n",
    "\n",
    "    return(RAW, grey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Example for estimating the Bosslike pipeline using $24 \\times 24$ macro-blocks as outputs. Here we only estimate the pipeline up to but not including downsampling. The corresponding downsampling matrix is already estimated as \"LANCZOS_down_nb3.npy\" in the filters/ folder.\n",
    "Beware that when downsampling, we need a higher macro-block size as inputs; we consequently also need more samples to estimate the matrix correctly. Here we set the number of images as $50$, the number can be a lot smaller when estimating pipelines without downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params=rawpy.Params(rawpy.DemosaicAlgorithm.PPG, half_size=False, four_color_rgb=False, \n",
    "                    use_camera_wb=True, use_auto_wb=False,user_wb=(1,1,1,1), \n",
    "                    output_color=rawpy.ColorSpace.raw, output_bps=16, \n",
    "                    user_flip=None, user_black=0, user_sat=None, \n",
    "                    no_auto_bright=True, auto_bright_thr=None, \n",
    "                    adjust_maximum_thr=0.0, bright=1.0, \n",
    "                    highlight_mode=rawpy.HighlightMode.Clip,  gamma=(1,1),\n",
    "                    exp_shift=None, exp_preserve_highlights=0.0, no_auto_scale=False,\n",
    "                    chromatic_aberration=None, bad_pixels_path=None,median_filter_passes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute(f):\n",
    "    size= 484\n",
    "    #print(f)\n",
    "    camera = dataset[f][0] \n",
    "    iso = dataset[f][1] \n",
    "    orientation=orient_dict[f]\n",
    "    lvl_max = dataset_max_val[camera+','+iso]\n",
    "    print(camera, iso, orientation)\n",
    "\n",
    "    a,b = noise_params[camera+','+iso]\n",
    "    M= 50\n",
    "    rb = np.zeros((M*size, 5476))\n",
    "    gb = np.zeros((M*size, 5184))\n",
    "    #rsb = np.zeros((M*size, 576))\n",
    "\n",
    "    for i in tqdm(np.arange(M)):\n",
    "        raw_im,greyim = generate_sample(path.join(RAW_path,f),orientation,a,b=b,lvl_max=lvl_max)\n",
    "        rb[i*size:(i+1)*size,:] = imc.block_row_scan(raw_im, 9, add_margin=True).reshape(-1, 5476)\n",
    "        gb[i*size:(i+1)*size,:]= imc.block_row_scan(greyim, 9, add_margin=False).reshape(-1, 5184)\n",
    "        #rsb[i*size:(i+1)*size,:]= imc.block_row_scan(rsim, 3, add_margin=False).reshape(-1, 576)\n",
    "    H0 = ridge_solve(rb, gb)\n",
    "    #np.save(path.join(filter_path, camera.replace(' ', '_') +'_'+str(orientation)  + '_BOSS_nb9_100N.npy'),H0.astype(np.float32))\n",
    "    return(H0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "H0 = compute(RAW_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(H0[:576,:576],vmin=-0.002, vmax=0.002)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4Lat estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     23,
     49
    ]
   },
   "outputs": [],
   "source": [
    "def sparsify(H, alpha=0.95, mode='csr', fast_mode=True, fast_N = 64):\n",
    "    \"\"\"\n",
    "    A general-purpose thresholder when the structure of the matrix is hard to describe.\n",
    "    (e.g, broken diagonals).\n",
    "    alpha gives the quantile which will be used as a threshold to zero the matrix coefficients.\n",
    "    Fast mode only uses the first N row of the matrix, useful for circulant matrix\n",
    "    Returns : A sparse csr matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    if not fast_mode:\n",
    "        q = np.quantile(np.abs(H.ravel()), alpha)\n",
    "    else:\n",
    "        q = np.quantile(np.abs(H[:fast_N,:].ravel()), alpha)\n",
    "    H_z = np.copy(H)\n",
    "    H_z[np.abs(H_z) <= q] = 0\n",
    "    if mode == 'csr':\n",
    "        spH = sp.csr_matrix(H_z)\n",
    "    elif mode == 'csc':\n",
    "        spH = sp.csc_matrix(H_z) \n",
    "    else:\n",
    "        print(\"Unsupported mode : {}\".format(mode))\n",
    "        return(None)\n",
    "    return(spH, q)\n",
    "def center_crop(im, newWidth, newHeight, add_margin=0):\n",
    "    width, height = im.shape[0:2]  # Get dimensions\n",
    "    if newWidth > width or newHeight > height:\n",
    "        newWidth, newHeight = newHeight, newWidth\n",
    "    \n",
    "# Here we simply compute the first and last indices of pixels' central area.\n",
    "    left = (width - newWidth) // 2\n",
    "    top = (height - newHeight) // 2\n",
    "    right = (width + newWidth) // 2\n",
    "    bottom = (height + newHeight) // 2\n",
    "# and merely return the pixels from this area ...\n",
    "    if add_margin==1:\n",
    "        return(im[left-1:right+1, top-1:bottom+1])\n",
    "    elif add_margin==3:\n",
    "        return(im[left-9:right+9, top-9:bottom+9])\n",
    "    elif add_margin==24:\n",
    "        return(im[left-24:right, top-24:bottom])\n",
    "    elif add_margin=='4latboss': #When resizing with resize factor 3\n",
    "        return(im[left-24-1:right+72+1, top-24-1:bottom+72+1])\n",
    "    elif add_margin=='4latlin': # if only cropping\n",
    "        return(im[left-8-1:right+24+1, top-8-1:bottom+24+1])\n",
    "    elif add_margin==0:\n",
    "        return(im[left:right, top:bottom])\n",
    "    else:\n",
    "        print('Unimplemented margin')\n",
    "        return(None)\n",
    "def get_raw_values(RAW_path, idx_x,idx_y, orientation, rf=1):\n",
    "    (h,w) = (264*rf, 264*rf)\n",
    "    RAW = rawpy.imread(RAW_path).raw_image_visible\n",
    "    if (orientation > 0):\n",
    "        print(\"Supposedly bad orientation\")\n",
    "        if orientation == 5:\n",
    "            RAW = np.rot90(RAW,1)\n",
    "        elif orientation == 6:\n",
    "            RAW = np.rot90(RAW,-1)\n",
    "        else:\n",
    "            print(\"Unknown orientation : {}\".format(orientation))\n",
    "            return(None)\n",
    "    #imc.rolling_row_scan(np.zeros((792+72, 792+72)), 9, stride=1, add_margin=True,clipped=False)[::3,::3]\n",
    "    if rf ==3:\n",
    "        raw_crop = center_crop(RAW,1920, 1920,add_margin='4latboss')[idx_x:idx_x+h+96+2, idx_y:idx_y+w+96+2]\n",
    "    else:\n",
    "        raw_crop = center_crop(RAW,1920, 1920,add_margin='4latlin')[idx_x:idx_x+h+32+2, idx_y:idx_y+w+32+2]\n",
    "    return(raw_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_lat_cov(RAW_path, f, H_DCT,rf = None):\n",
    "    f_path = path.join(RAW_path,f)\n",
    "    idx_x, idx_y = im_idx[f.split('.')[0]]\n",
    "    idx_x, idx_y = int(idx_x), int(idx_y)\n",
    "    orientation = orient_dict[f]\n",
    "\n",
    "\n",
    "\n",
    "    camera = dataset[f][0]\n",
    "    iso = dataset[f][1]\n",
    "    a,b  = noise_params[camera + ',' + iso]\n",
    "    lvl_max = dataset_max_val[camera + ',' + iso]\n",
    "\n",
    "\n",
    "    if rf is not None:\n",
    "        rb = imc.rolling_row_scan(get_raw_values(f_path, idx_x, idx_y, orientation,rf=3), 9, stride=3, add_margin=True, clipped=False)\n",
    "        spH = np.load(path.join(filter_path, camera.replace(' ', '_') +'_'+str(orientation) +'_BOSS_nb9_100N_sparse.npy'), allow_pickle=True).item()\n",
    "\n",
    "    else:\n",
    "        r = get_raw_values(f_path, idx_x, idx_y, orientation,rf=1)\n",
    "        rb = imc.rolling_row_scan(r, 3, stride=1, add_margin=True, clipped=False)\n",
    "        spH = np.load(path.join(filter_path, camera.replace(' ', '_') +'_'+str(orientation) +'_LIN_nb3_100N_sparse.npy'), allow_pickle=True).item()\n",
    "\n",
    "\n",
    "    L1,L2,L3, L4 = estimate_4lat(rb,a,b,spH,H_DCT,lvl_max=lvl_max)\n",
    "    np.save(path.join(save_path, 'L1_' + f.split('.')[0]), L1)\n",
    "    np.save(path.join(save_path, 'L2_' + f.split('.')[0]), L2)\n",
    "    np.save(path.join(save_path, 'L3_' + f.split('.')[0]), L3)\n",
    "    np.save(path.join(save_path, 'L4_' + f.split('.')[0]), L4)\n",
    "    return(L1,L2,L3, L4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of setup for estimating ready-to use covariance matrices of the 4Lat model for the Bosslike pipeline.\n",
    "The estimation is optimized using sparse matrices. The estimation can be sped up bu using sparser matrices through the provided sparsify() method. Note though that sparse matrices can only be used up to but not including the DCT matrix which destroys the high sparsity of the covariance matrix before this operation.\n",
    "\n",
    "The file structure of the covariance matrices has also been optimized for fast loading and low file size. Despite this, beware that the 4Lat model using $24\\times24$ macro-blocks necessitate a lot of data and leads to somewhat heavy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = path.join(base_path, 'LIN/4Lat_cov/')\n",
    "if not path.isdir(save_path): makedirs(save_path)\n",
    "filter_path = path.join(base_path, 'LIN/filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_DCT = generate_DCT_trans(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1, L2, L3, L4 = compute_lat_cov(RAW_path, RAW_files[2], H_DCT,rf = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=8)(delayed(compute_lat_cov)(RAW_path, f, H_DCT,rf = 3) for f in tqdm(RAW_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4Lat estimation without RAW file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from code.Lat_cov_estimation_noRAW import estimate_4lat_noRAW, estimate_DCT_hetero_model, estimate_variance_from_dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Estimate $c_1^{DC}$ and $c_2^{DC}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def estimate_all_image_model(f, dataset, noise_params, orient_dict):\n",
    "    fn = f.split('.')[0]\n",
    "\n",
    "    j_im = np.load(path.join(precover_path, fn + '.jpg.npy' ))\n",
    "    orientation = orient_dict[f]\n",
    "    camera = dataset[f][0]\n",
    "    iso = dataset[f][1]\n",
    "    a,b  = noise_params[camera + ',' + iso]\n",
    "    max_v = dataset_max_val[camera + ',' + iso]\n",
    "    if pipeline_key == 'Bosslike':\n",
    "        H0 = np.load(path.join(filter_path, camera.replace(' ', '_') +'_'+str(orientation) +'_BOSS_nb3_100N.npy'))\n",
    "        H_down = np.load(path.join(filter_path, 'LANCZOS_down_nb1.npy'))\n",
    "        H0 = H_down @ H0\n",
    "        aDC, bDC = estimate_DCT_hetero_model(imc.compute_spatial_domain(j_im, np.ones((8,8))), a,b,H0, max_v,rf=3)\n",
    "    elif pipeline_key == 'LIN':\n",
    "        H0 = np.load(path.join(filter_path, camera.replace(' ', '_') +'_'+str(orientation) +'_LIN_nb1_100N.npy'))\n",
    "        aDC, bDC = estimate_DCT_hetero_model(imc.compute_spatial_domain(j_im, np.ones((8,8))), a,b,H0, max_v)\n",
    "    else:\n",
    "        print(\"This pipeline is not available\")\n",
    "        return(None)\n",
    "    np.save(path.join(save_path, fn + '.npy'), {'a':aDC, 'b':bDC})\n",
    "    return(aDC, bDC)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipeline_key = 'LIN'\n",
    "save_path = path.join(base_path,  pipeline_key , 'noRAW_model')\n",
    "if not path.isdir(save_path):makedirs(save_path)\n",
    "filter_path = path.join(base_path, pipeline_key ,'filters')\n",
    "precover_path = path.join(base_path, pipeline_key, 'QF100/precover/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimate_all_image_model('908.cr2', dataset, noise_params, orient_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Scale correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scale_correlation_matrix(f):\n",
    "\n",
    "        fn = f.split('.')[0]\n",
    "        camera = dataset[f][0] \n",
    "        orientation=orient_dict[f]\n",
    "        C_corr = np.load(path.join(base_path, pipeline_key, 'corr_matrix', camera.replace(' ', '_') +'_'+str(orientation) + '.npy'))\n",
    "        noise_model = np.load(path.join(noise_model_path, fn + '.npy'), allow_pickle=True).item()\n",
    "        dc_model = np.load(path.join(dc_model_path, camera + '.npy'))\n",
    "        j_im = np.load(path.join(precover_path, fn + '.jpg.npy'))\n",
    "        L1, L2, L3, L4 = estimate_4lat_noRAW(j_im,noise_model, dc_model, C_corr)\n",
    "        \n",
    "        np.save(path.join(save_path, 'L1_' + fn), L1.astype(np.float32))\n",
    "        np.save(path.join(save_path, 'L2_' + fn), L2.astype(np.float32))\n",
    "        np.save(path.join(save_path, 'L3_' + fn), L3.astype(np.float32))\n",
    "        np.save(path.join(save_path, 'L4_' + fn), L4.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dc_model_path = path.join(base_path, pipeline_key, 'dc_models')#np.load('Bosslike_mean_dc_model.npy')\n",
    "noise_model_path = path.join(base_path, pipeline_key, 'noRAW_model')\n",
    "save_path = path.join(base_path, pipeline_key, '4Lat_cov_noRAW/')\n",
    "if not path.isdir(save_path):makedirs(save_path)\n",
    "precover_path = path.join(base_path, pipeline_key, 'QF100/precover/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scale_correlation_matrix('908.cr2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
