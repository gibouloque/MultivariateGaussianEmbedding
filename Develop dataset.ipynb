{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import code.image_conversions as imc\n",
    "\n",
    "\n",
    "\n",
    "import jpegio as jio\n",
    "from os import listdir, path,mkdir,makedirs\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy.random as npr\n",
    "\n",
    "import rawpy\n",
    "\n",
    "from code.image_tools  import edge_crop,center_crop\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7,
     18,
     29
    ]
   },
   "outputs": [],
   "source": [
    "comp_info = [{'ac_tbl_no': 0,\n",
    "  'component_id': 1,\n",
    "  'dc_tbl_no': 0,\n",
    "  'h_samp_factor': 1,\n",
    "  'quant_tbl_no': 0,\n",
    "  'v_samp_factor': 1}]\n",
    "\n",
    "c_quant_95 = np.array([\\\n",
    "        [ 2,  1,  1,  2,  2,  4,  5,  6],\\\n",
    "        [ 1,  1,  1,  2,  3,  6,  6,  6],\\\n",
    "        [ 1,  1,  2,  2,  4,  6,  7,  6],\\\n",
    "        [ 1,  2,  2,  3,  5,  9,  8,  6],\\\n",
    "        [ 2,  2,  4,  6,  7, 11, 10,  8],\\\n",
    "        [ 2,  4,  6,  6,  8, 10, 11,  9],\\\n",
    "        [ 5,  6,  8,  9, 10, 12, 12, 10],\\\n",
    "        [ 7,  9, 10, 10, 11, 10, 10, 10]])\n",
    "\n",
    "# Quant table at 85% (convert)\n",
    "c_quant_85 = np.array([\\\n",
    "     [ 5,  3,  3,  5,  7, 12, 15, 18],\\\n",
    "     [ 4,  4,  4,  6,  8, 17, 18, 17],\\\n",
    "     [ 4,  4,  5,  7, 12, 17, 21, 17],\\\n",
    "     [ 4,  5,  7,  9, 15, 26, 24, 19],\\\n",
    "     [ 5,  7, 11, 17, 20, 33, 31, 23],\\\n",
    "     [ 7, 11, 17, 19, 24, 31, 34, 28],\\\n",
    "     [15, 19, 23, 26, 31, 36, 36, 30],\\\n",
    "     [22, 28, 29, 29, 34, 30, 31, 30]])\n",
    "\n",
    "# Quant table at 75% (convert)\n",
    "c_quant_75 = np.array([\\\n",
    "        [ 8,  6,  5,  8, 12, 20, 26, 31],\\\n",
    "        [ 6,  6,  7, 10, 13, 29, 30, 28],\\\n",
    "        [ 7,  7,  8, 12, 20, 29, 35, 28],\\\n",
    "        [ 7,  9, 11, 15, 26, 44, 40, 31],\\\n",
    "        [ 9, 11, 19, 28, 34, 55, 52, 39],\\\n",
    "        [12, 18, 28, 32, 41, 52, 57, 46],\\\n",
    "        [25, 32, 39, 44, 52, 61, 60, 51],\\\n",
    "        [36, 46, 48, 49, 56, 50, 52, 50]])\n",
    "\n",
    "def convert_npy_to_jpeg(im_dct, outpath, imname, QF=100):\n",
    "    im_dct = np.round(im_dct)\n",
    "\n",
    "\n",
    "    #im_tmp = (Image.fromarray(im_dct*0+127)).convert('L')\n",
    "    #im_tmp.save(path.join(outpath, imname))\n",
    "    if QF==100:\n",
    "        I_struct = jio.read(path.join('data/skeleton_QF100.jpg'))\n",
    "    elif QF==95:\n",
    "        I_struct = jio.read(path.join('data/jpeg_skeleton_QF95.jpg'))\n",
    "    elif QF==85:\n",
    "        I_struct = jio.read(path.join('data/jpeg_skeleton_QF85.jpg'))\n",
    "    elif QF==75:\n",
    "        I_struct = jio.read(path.join('data/jpeg_skeleton_QF75.jpg'))\n",
    "    else:\n",
    "        print(\"No available skeleton for QF {}\".format(QF))\n",
    "        return(None)\n",
    "    \n",
    "    I_struct.coef_arrays[0][:,:] = im_dct[:,:]\n",
    "    I_struct.optimize_coding = True\n",
    "    try:\n",
    "        I_struct.write(path.join(outpath, imname))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to save jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "comp_info = [{'ac_tbl_no': 0,\n",
    "  'component_id': 1,\n",
    "  'dc_tbl_no': 0,\n",
    "  'h_samp_factor': 1,\n",
    "  'quant_tbl_no': 0,\n",
    "  'v_samp_factor': 1}]\n",
    "\n",
    "def develop_jpeg(grey, outpaths, imname, QFs=[100], save_precover=False):\n",
    "    for i,QF in enumerate(QFs):\n",
    "            if  QF == 100:\n",
    "                c_quant = np.ones((8,8))\n",
    "            elif QF == 95:\n",
    "                c_quant = quant_95\n",
    "            elif QF == 85:\n",
    "                c_quant = quant_85\n",
    "            elif QF == 75:\n",
    "                c_quant = quant_75\n",
    "            if save_precover:\n",
    "                    im_dct = imc.compute_dct_domain(grey, c_quant)\n",
    "                    (h,w)= im_dct.shape\n",
    "                    im_dct = im_dct[0:8*(h//8), 0:8*(w//8)]\n",
    "                    np.save(path.join(outpaths[i], 'precover', imname), im_dct)\n",
    "                    im_dct = np.round(im_dct)\n",
    "            else:\n",
    "                    im_dct = imc.compute_jpeg_domain(grey, c_quant)\n",
    "                    (h,w)= im_dct.shape\n",
    "                    im_dct = im_dct[0:8*(h//8), 0:8*(w//8)]\n",
    "                    im_dct = np.round(im_dct)\n",
    "\n",
    "\n",
    "            convert_npy_to_jpeg(im_dct, outpaths[i], imname, QF=QF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def develop_image(i, params, idx_x, idx_y, RAW_path, jpeg_path, rf=3):\n",
    "\n",
    "\n",
    "    if not path.isdir(path.join(jpeg_path, 'precover')):\n",
    "        makedirs(path.join(jpeg_path, 'precover'))\n",
    "\n",
    "    RAW_im = rawpy.imread(RAW_path)\n",
    "    f = str(i)\n",
    "\n",
    "    rgb = RAW_im.postprocess(params)\n",
    "    (h,w) = RAW_im.raw_image_visible.shape\n",
    "\n",
    "    crop_shape = 264\n",
    "\n",
    "    grey = center_crop(imc.rgb2gray(rgb/(2**16-1)*255),1920, 1920)[idx_x:idx_x+crop_shape*rf, idx_y:idx_y+crop_shape*rf]\n",
    "\n",
    "    if rf !=1:\n",
    "        res_im = np.array(Image.fromarray(grey[:,:]).resize((crop_shape, crop_shape), Image.LANCZOS))\n",
    "        develop_jpeg(res_im, [jpeg_path], f+'.jpg', QFs=[100], save_precover=True)\n",
    "    else:\n",
    "        develop_jpeg(grey, [jpeg_path], f+'.jpg', QFs=[100], save_precover=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsLIN=rawpy.Params(rawpy.DemosaicAlgorithm.LINEAR, half_size=False, four_color_rgb=False, \n",
    "                    use_camera_wb=False, use_auto_wb=False,user_wb=(1,1,1,1), \n",
    "                    output_color=rawpy.ColorSpace.raw, output_bps=16, \n",
    "                    user_flip=None, user_black=0, user_sat=None, \n",
    "                    no_auto_bright=True, auto_bright_thr=None, \n",
    "                    adjust_maximum_thr=0.0, bright=1.0, \n",
    "                    highlight_mode=rawpy.HighlightMode.Clip,  gamma=(1,1),\n",
    "                    exp_shift=None, exp_preserve_highlights=0.0, no_auto_scale=False,\n",
    "                    chromatic_aberration=None, bad_pixels_path=None,median_filter_passes=0)\n",
    "paramsBosslike=rawpy.Params(rawpy.DemosaicAlgorithm.PPG, half_size=False, four_color_rgb=False, \n",
    "                    use_camera_wb=True, use_auto_wb=False,user_wb=(1,1,1,1), \n",
    "                    output_color=rawpy.ColorSpace.raw, output_bps=16, \n",
    "                    user_flip=None, user_black=0, user_sat=None, \n",
    "                    no_auto_bright=True, auto_bright_thr=None, \n",
    "                    adjust_maximum_thr=0.0, bright=1.0, \n",
    "                    highlight_mode=rawpy.HighlightMode.Clip,  gamma=(1,1),\n",
    "                    exp_shift=None, exp_preserve_highlights=0.0, no_auto_scale=False,\n",
    "                    chromatic_aberration=None, bad_pixels_path=None,median_filter_passes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_params = np.load('data/BOSSBase/BOSS_noise_params_robust.npy', allow_pickle=True).item()\n",
    "dataset = np.load('data/BOSSBase/BOSSBase_dataset.npy', allow_pickle=True).item()\n",
    "orient_dict = np.load('data/BOSSBase/orient_dict_BossBase.npy', allow_pickle=True).item()\n",
    "dataset_max_val = np.load('data/BOSSBase/Camera_BOSS_max_val.npy', allow_pickle=True).item()\n",
    "im_idx = np.load('data/BOSSBase/BOSS_edge_crop_idx.npy', allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'datasets/BOSSBase/'\n",
    "RAW_path = path.join( base_path, 'RAW')\n",
    "RAW_files = listdir(RAW_path)\n",
    "\n",
    "# Remove M9\n",
    "RAW_files = [f for f in RAW_files if dataset[f][0] != 'M9 Digital Camera']\n",
    "RAW_files_path = [RAW_path + file for file in RAW_files if path.isfile(RAW_path + file)]\n",
    "\n",
    "jpeg_path = path.join(base_path, 'Bosslike/QF100/')\n",
    "\n",
    "\n",
    "if not path.isdir(jpeg_path):\n",
    "    makedirs(jpeg_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next functions are used to develop the same image as in the paper, using the same crops without having to use the costly *edge_crop* function by directly giving the cropping indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def computeBOSS(f):\n",
    "    fn = f.split('.')[0]\n",
    "    idx_x, idx_y = im_idx[fn]\n",
    "    idx_x, idx_y = int(idx_x), int(idx_y)\n",
    "    develop_image(fn, paramsBosslike, idx_x, idx_y, path.join(RAW_path, f), jpeg_path,rf=3 )\n",
    "def computeLIN(f):\n",
    "    fn = f.split('.')[0]\n",
    "    idx_x, idx_y = im_idx[fn]\n",
    "    idx_x, idx_y = int(idx_x), int(idx_y)\n",
    "    develop_image(fn, paramsLIN, idx_x, idx_y, path.join(RAW_path, f), jpeg_path,rf=1  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeLIN(f=RAW_files[0]) \n",
    "computeBOSS(f=RAW_files[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=15)(delayed(computeBOSS)(f=f) for f in tqdm(RAW_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
